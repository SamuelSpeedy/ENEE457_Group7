"""
ML-Based Malware Detection using EMBER Dataset

Demonstrates the malware detection workflow:
1. Load dataset
2. Preprocess data
3. Train models
4. Evaluate and visualize results
"""

import os
import sys
import time
from pathlib import Path
from typing import Tuple, Dict, Any

import ember
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, roc_auc_score, roc_curve
)
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb

# Configuration
DATA_DIR = Path("./ember_data")
RESULTS_DIR = Path("./results")
RANDOM_SEED = 42

# Create directories
DATA_DIR.mkdir(exist_ok=True)
RESULTS_DIR.mkdir(exist_ok=True)

print("="*80)
print("ML-Based Malware Detection Workflow")
print("="*80)


def download_ember_dataset():
    """
    Download the EMBER 2018 dataset if not present.
    """
    print("\n[STEP 1: Checking for EMBER Dataset]")
    if (DATA_DIR / "train_features.jsonl").exists():
        print("Dataset already downloaded.")
        return

    print("Downloading dataset (this may take 10-20 minutes)...")
    try:
        ember.create_vectorized_features(str(DATA_DIR))
        print("Dataset downloaded successfully.")
    except Exception as e:
        print(f"Error downloading dataset: {e}")
        print("Please download manually from https://github.com/elastic/ember")
        sys.exit(1)


def load_ember_data() -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    Load EMBER train and test sets.
    """
    print("\n[STEP 2: Loading EMBER Data]")
    X_train, y_train = ember.read_vectorized_features(str(DATA_DIR), subset="train")
    X_test, y_test = ember.read_vectorized_features(str(DATA_DIR), subset="test")

    print(f"  Training samples: {X_train.shape[0]:,}")
    print(f"  Test samples: {X_test.shape[0]:,}")
    print(f"  Features per sample: {X_train.shape[1]:,}")
    return X_train, y_train, X_test, y_test


def preprocess_data(X_train: np.ndarray, y_train: np.ndarray,
                   X_test: np.ndarray, y_test: np.ndarray) -> Tuple:
    """
    Preprocess data:
    1. Remove unlabeled samples (y == -1)
    2. Handle missing values (NaN)
    """
    print("\n[STEP 3: Preprocessing Data]")

    # Remove unlabeled samples
    train_mask = y_train != -1
    test_mask = y_test != -1

    X_train, y_train = X_train[train_mask], y_train[train_mask]
    X_test, y_test = X_test[test_mask], y_test[test_mask]

    print(f"  Filtered training samples: {X_train.shape[0]:,}")
    print(f"  Filtered test samples: {X_test.shape[0]:,}")

    # Handle missing values
    X_train = np.nan_to_num(X_train, nan=0.0)
    X_test = np.nan_to_num(X_test, nan=0.0)
    print("  Missing values handled.")
    return X_train, y_train, X_test, y_test


def train_model(model: Any, X_train: np.ndarray, y_train: np.ndarray,
                model_name: str) -> Any:
    """
    Train a given model on a sample of the data.
    """
    print(f"\n[STEP 4: Training {model_name}]")

    # Train on a sample for speed.
    # For the final project, use the full dataset on Colab.
    sample_size = min(10000, len(X_train))
    print(f"  Training on a sample of {sample_size:,} instances for this demo.")
    indices = np.random.choice(len(X_train), sample_size, replace=False)
    X_sample, y_sample = X_train[indices], y_train[indices]

    start_time = time.time()
    model.fit(X_sample, y_sample)
    train_time = time.time() - start_time
    print(f"  {model_name} trained in {train_time:.1f} seconds.")
    return model


def evaluate_model(model: Any, X_test: np.ndarray, y_test: np.ndarray,
                  model_name: str) -> Dict[str, float]:
    """
    Evaluate model performance and generate visualizations.
    """
    print(f"\n[STEP 5: Evaluating {model_name}]")
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]

    # Calculate metrics
    metrics = {
        'accuracy': accuracy_score(y_test, y_pred),
        'precision': precision_score(y_test, y_pred),
        'recall': recall_score(y_test, y_pred),
        'f1_score': f1_score(y_test, y_pred),
        'roc_auc': roc_auc_score(y_test, y_pred_proba)
    }

    # False positive rate
    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
    metrics['false_positive_rate'] = fp / (fp + tn)

    # Display results
    print(f"  Performance Metrics for {model_name}:")
    for key, value in metrics.items():
        print(f"    {key:<20}: {value:.4f}")

    # Visualizations
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    fig.suptitle(f"{model_name} Evaluation")

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Benign', 'Malicious'],
                yticklabels=['Benign', 'Malicious'],
                ax=axes[0])
    axes[0].set_ylabel('Actual')
    axes[0].set_xlabel('Predicted')
    axes[0].set_title('Confusion Matrix')

    # ROC Curve
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
    axes[1].plot(fpr, tpr, label=f'ROC (AUC = {metrics["roc_auc"]:.3f})', linewidth=2)
    axes[1].plot([0, 1], [0, 1], 'k--', label='Random Classifier')
    axes[1].set_xlabel('False Positive Rate')
    axes[1].set_ylabel('True Positive Rate')
    axes[1].set_title('ROC Curve')
    axes[1].legend()

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    save_path = RESULTS_DIR / f"{model_name.lower().replace(' ', '_')}_evaluation.png"
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"  Evaluation plots saved to: {save_path}")
    plt.close()

    return metrics


def main():
    """Main execution flow"""
    download_ember_dataset()
    X_train, y_train, X_test, y_test = load_ember_data()
    X_train, y_train, X_test, y_test = preprocess_data(
        X_train, y_train, X_test, y_test
    )

    # Random Forest (Baseline)
    rf_model = RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        random_state=RANDOM_SEED,
        n_jobs=-1,
    )
    rf_model = train_model(rf_model, X_train, y_train, "Random Forest")
    rf_metrics = evaluate_model(rf_model, X_test, y_test, "Random Forest")

    # XGBoost (Primary Model)
    xgb_model = xgb.XGBClassifier(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        objective='binary:logistic',
        eval_metric='logloss',
        random_state=RANDOM_SEED,
        n_jobs=-1,
    )
    xgb_model = train_model(xgb_model, X_train, y_train, "XGBoost")
    xgb_metrics = evaluate_model(xgb_model, X_test, y_test, "XGBoost")

    # Final Comparison
    print("\n[STEP 6: Model Comparison]")
    comparison_df = pd.DataFrame({
        'Random Forest': rf_metrics,
        'XGBoost': xgb_metrics
    }).T

    print(comparison_df)
    comparison_df.to_csv(RESULTS_DIR / "model_comparison.csv")
    print(f"  Comparison saved to: {RESULTS_DIR / 'model_comparison.csv'}")

    print("\nWorkflow complete. Results are in the 'results' directory.")


if __name__ == "__main__":
    main()